[{"authors":null,"categories":null,"content":"After a PhD in Inria Nancy Grand-Est entitled “alpha-stable process for signal processing”, Mathieu Fontaine was a Postdoc from October 2019 to August 2021 at RIKEN Artificial Intelligence Project (AIP) and became a guest at Kyoto University. He is now Associate Professor in Télécom Paris. His interests is mainly on machine listening including, but not limited, to speech enhancement, speaker separation, source localization and music source separation using heavy-tailed probabilistic models and/or deep bayesian networks with also applications in augmented reality.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://matfontaine.github.io/author/mathieu-fontaine/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/mathieu-fontaine/","section":"authors","summary":"After a PhD in Inria Nancy Grand-Est entitled “alpha-stable process for signal processing”, Mathieu Fontaine was a Postdoc from October 2019 to August 2021 at RIKEN Artificial Intelligence Project (AIP) and became a guest at Kyoto University.","tags":null,"title":"Mathieu Fontaine","type":"authors"},{"authors":["Kazuyoshi Yoshii","Kouhei Sekiguchi","Yoshiaki Bando","Mathieu Fontaine","Aditya Arie Nugraha"],"categories":[],"content":"","date":1633801872,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1633801872,"objectID":"a0a121ec3030898a5b14304fcd9e93ca","permalink":"https://matfontaine.github.io/publication/yoshii-fast-nodate/","publishdate":"2021-10-09T17:51:12.146369Z","relpermalink":"/publication/yoshii-fast-nodate/","section":"publication","summary":"","tags":[],"title":"Fast Multichannel Correlated Tensor Factorization for Blind Source Separation","type":"publication"},{"authors":["Mathieu Fontaine","Kouhei Sekiguchi","Aditya Arie Nugraha","Yoshiaki Bando","Kazuyoshi Yoshii"],"categories":[],"content":"","date":1627776000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1633801873,"objectID":"8962adfcc628f2cd8d4b82b6de56a6b8","permalink":"https://matfontaine.github.io/publication/fontaine-alpha-stable-2021/","publishdate":"2021-10-09T17:51:13.256733Z","relpermalink":"/publication/fontaine-alpha-stable-2021/","section":"publication","summary":"","tags":[],"title":"Alpha-Stable Autoregressive Fast Multichannel Nonnegative Matrix Factorization for Joint Speech Enhancement and Dereverberation","type":"publication"},{"authors":["Kouhei Sekiguchi","Yoshiaki Bando","Aditya Arie Nugraha","Mathieu Fontaine","Kazuyoshi Yoshii"],"categories":[],"content":"","date":1622505600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1633801873,"objectID":"072d2b209871db3ddc2076e13ce0e073","permalink":"https://matfontaine.github.io/publication/sekiguchi-autoregressive-2021/","publishdate":"2021-10-09T17:51:12.881716Z","relpermalink":"/publication/sekiguchi-autoregressive-2021/","section":"publication","summary":"This paper describes a joint blind source separation and dereverberation method that works adaptively and efficiently in a reverberant noisy environment. The modern approach to blind source separation (BSS) is to formulate a probabilistic model of multichannel mixture signals that consists of a source model representing the time-frequency structures of source spectrograms and a spatial model representing the inter-channel covariance structures of source images. The cutting-edge BSS method in this thread of research is fast multi-channel nonnegative matrix factorization (FastMNMF) that consists of a low-rank source model based on nonnegative matrix factorization (NMF) and a full-rank spatial model based on jointly-diagonalizable spatial covariance matrices. Although FastMNMF is computationally efficient and can deal with both directional sources and diffuse noise simultaneously, its performance is severely degraded in a reverberant environment. To solve this problem, we propose autoregressive FastMNMF (AR-FastMNMF) based on a unified probabilistic model that combines FastMNMF with a blind dereverberation method called weighted prediction error (WPE), where all the parameters are optimized jointly such that the likelihood for observed reverberant mixture signals is maximized. Experimental results showed the superiority of AR-FastMNMF over conventional methods that perform blind dereverberation and BSS jointly or sequentially.","tags":["\"Adaptation models\"","\"blind dereverberation\"","\"Blind source separation\"","\"Computational modeling\"","\"joint diagonalization\"","\"multichannel nonnegative matrix factorization\"","\"Noise measurement\"","\"Probabilistic logic\"","\"Reverberation\"","\"Time-frequency analysis\""],"title":"Autoregressive Fast Multichannel Nonnegative Matrix Factorization For Joint Blind Source Separation And Dereverberation","type":"publication"},{"authors":["Kazuyoshi Yoshii","Kouhei Sekiguchi","Yoshiaki Bando","Mathieu Fontaine","Aditya Arie Nugraha"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615889018,"objectID":"84d90e8a19e26e92cb433d6878fa9781","permalink":"https://matfontaine.github.io/publication/yoshii-2021-fast/","publishdate":"2021-03-16T10:04:15.471193Z","relpermalink":"/publication/yoshii-2021-fast/","section":"publication","summary":"","tags":[],"title":"Fast Multichannel Correlated Tensor Factorization for Blind Source Separation","type":"publication"},{"authors":["Yoshiaki Bando","Kouhei Sekiguchi","Yoshiki Masuyama","Aditya Arie Nugraha","Mathieu Fontaine","Kazuyoshi Yoshii"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1633801873,"objectID":"a66d52f53639dfe3622f41673ea777a4","permalink":"https://matfontaine.github.io/publication/bando-neural-2021/","publishdate":"2021-10-09T17:51:13.066341Z","relpermalink":"/publication/bando-neural-2021/","section":"publication","summary":"This paper describes aneural blind source separation (BSS) method based on amortized variational inference (AVI) of a non-linear generative model of mixture signals. A classical statistical approach to BSS is to fit a linear generative model that consists of spatial and source models representing the inter-channel covariances and power spectral densities of sources, respectively. Although the variational autoencoder (VAE) has successfully been used as a non-linear source model with latent features, it should be pretrained from a sufficient amount of isolated signals. Our method, in contrast, enables the VAE-based source model to be trained only from mixture signals. Specifically, we introduce a neural mixture-to-feature inference model that directly infers the latent features from the observed mixture and integrate it with a neural feature-to-mixture generative model consisting of a full-rank spatial model and a VAE-based source model. All the models are optimized jointly such that the likelihood for the training mixtures is maximized in the framework of AVI. Once the inference model is optimized, it can be used for estimating the latent features of sources included in unseen mixture signals. The experimental results show that the proposed method outperformed the state-of-the-art BSS methods based on linear generative models and was comparable to a method based on supervised learning of the VAE-based sourcemodel.","tags":["\"Analytical models\"","\"Computational modeling\"","\"Decoding\"","\"deep generative models\"","\"Neural networks\"","\"Neural source separation\"","\"Predictive models\"","\"Reverberation\"","\"Training\"","\"unsupervised training\"","\"variational autoencoders\""],"title":"Neural Full-Rank Spatial Covariance Analysis for Blind Source Separation","type":"publication"},{"authors":["Yicheng Du","Kouhei Sekiguchi","Yoshiaki Bando","Aditya Arie Nugraha","Mathieu Fontaine","Kazuyoshi Yoshii","Tatsuya Kawahara"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615889017,"objectID":"79a66b2024804171f15feb8352fcdddb","permalink":"https://matfontaine.github.io/publication/du-2021-semi/","publishdate":"2021-03-16T10:04:15.164482Z","relpermalink":"/publication/du-2021-semi/","section":"publication","summary":"","tags":[],"title":"Semi-supervised Multichannel Speech Separation Based on a Phone-and Speaker-Aware Deep Generative Model of Speech Spectrograms","type":"publication"},{"authors":["Aditya Arie Nugraha","Kouhei Sekiguchi","Mathieu Fontaine","Yoshiaki Bando","Kazuyoshi Yoshii"],"categories":[],"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615889017,"objectID":"f663f441704b7cd49167e773cd65b70c","permalink":"https://matfontaine.github.io/publication/nugraha-2020-flow/","publishdate":"2021-03-16T10:04:15.31581Z","relpermalink":"/publication/nugraha-2020-flow/","section":"publication","summary":"","tags":[],"title":"Flow-Based Independent Vector Analysis for Blind Source Separation","type":"publication"},{"authors":["Mathieu Fontaine","Roland Badeau","Antoine Liutkus"],"categories":[],"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1608716510,"objectID":"c107f69bfdf7c890f7aee8d5c42798a2","permalink":"https://matfontaine.github.io/publication/fontaine-separation-2020/","publishdate":"2021-03-16T10:04:14.543229Z","relpermalink":"/publication/fontaine-separation-2020/","section":"publication","summary":"","tags":[],"title":"Separation of alpha-stable random vectors","type":"publication"},{"authors":["Mathieu Fontaine","Kouhei Sekiguchi","Aditya Arie Nugraha","Kazuyoshi Yoshii"],"categories":[],"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1608716510,"objectID":"6733284b4f591c728103ec9ab5973af4","permalink":"https://matfontaine.github.io/publication/fontaine-unsupervised-2020/","publishdate":"2021-03-16T10:04:14.69489Z","relpermalink":"/publication/fontaine-unsupervised-2020/","section":"publication","summary":"","tags":[],"title":"Unsupervised Robust Speech Enhancement Based on Alpha-Stable Fast Multichannel Nonnegative Matrix Factorization","type":"publication"},{"authors":["Mathieu Fontaine","Aditya Arie Nugraha","Roland Badeau","Kazuyoshi Yoshii","Antoine Liutkus"],"categories":[],"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1608716510,"objectID":"68cf36e3cfa8bda3507e1d8c1e9b1503","permalink":"https://matfontaine.github.io/publication/fontaine-cauchy-2019/","publishdate":"2021-03-16T10:04:15.001195Z","relpermalink":"/publication/fontaine-cauchy-2019/","section":"publication","summary":"","tags":[],"title":"Cauchy multichannel speech enhancement with a deep speech prior","type":"publication"},{"authors":["Mathieu Fontaine"],"categories":[],"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1608716509,"objectID":"a27276c91a05e7fd2b55490b72a70498","permalink":"https://matfontaine.github.io/publication/fontaine-processus-2019/","publishdate":"2021-03-16T10:04:13.907421Z","relpermalink":"/publication/fontaine-processus-2019/","section":"publication","summary":"","tags":[],"title":"Processus alpha-stables pour le traitement du signal","type":"publication"},{"authors":["Mathieu Fontaine","Fabian-Robert Stöter","Antoine Liutkus","Umut Şimşekli","Romain Serizel","Roland Badeau"],"categories":[],"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1608716510,"objectID":"6ebc84e9ccaf85abd79d44be2580fb05","permalink":"https://matfontaine.github.io/publication/fontaine-multichannel-2018/","publishdate":"2021-03-16T10:04:14.84741Z","relpermalink":"/publication/fontaine-multichannel-2018/","section":"publication","summary":"","tags":[],"title":"Multichannel audio modeling with elliptically stable tensor decomposition","type":"publication"},{"authors":["Mathieu Fontaine","Fabian-Robert Stöter","Antoine Liutkus","Umut Şimşekli","Romain Serizel","Roland Badeau"],"categories":[],"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1633801871,"objectID":"97b646ddfb4ec262e86ac8b6097bb29e","permalink":"https://matfontaine.github.io/publication/deville-multichannel-2018/","publishdate":"2021-10-09T17:51:11.78404Z","relpermalink":"/publication/deville-multichannel-2018/","section":"publication","summary":"This paper introduces a new method for multichannel speech enhancement based on a versatile modeling of the residual noise spectrogram. Such a model has already been presented before in the single channel case where the noise component is assumed to follow an alphastable distribution for each time-frequency bin, whereas the speech spectrogram, supposed to be more regular, is modeled as Gaussian. In this paper, we describe a multichannel extension of this model, as well as a Monte Carlo Expectation - Maximisation algorithm for parameter estimation. In particular, a multichannel extension of the Itakura-Saito nonnegative matrix factorization is exploited to estimate the spectral parameters for speech, and a Metropolis-Hastings algorithm is proposed to estimate the noise contribution. We evaluate the proposed method in a challenging multichannel denoising application and compare it to other state-of-the-art algorithms.","tags":[],"title":"Multichannel Audio Modeling with Elliptically Stable Tensor Decomposition","type":"publication"},{"authors":["M. Fontaine","A. Liutkus","L. Girin","R. Badeau"],"categories":[],"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615889017,"objectID":"2a34a6e5fe964e80034ff2b8b9a060ed","permalink":"https://matfontaine.github.io/publication/explainingfontaine-17/","publishdate":"2021-03-16T10:04:14.37585Z","relpermalink":"/publication/explainingfontaine-17/","section":"publication","summary":"","tags":[],"title":"Explaining the parameterized wiener filter with alpha-stable processes","type":"publication"},{"authors":["Mathieu Fontaine","Antoine Liutkus","Laurent Girin","Roland Badeau"],"categories":[],"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1633801872,"objectID":"eb275a0089306990780983585e233d6b","permalink":"https://matfontaine.github.io/publication/fontaine-explaining-2017/","publishdate":"2021-10-09T17:51:12.329143Z","relpermalink":"/publication/fontaine-explaining-2017/","section":"publication","summary":"","tags":[],"title":"Explaining the parameterized Wiener filter with alpha-stable processes","type":"publication"},{"authors":["Mathieu Fontaine","Charles Vanwynsberghe","Antoine Liutkus","Roland Badeau"],"categories":[],"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1633801872,"objectID":"a9436c86a5caedc8d05af0658fb78dfd","permalink":"https://matfontaine.github.io/publication/fontaine-scalable-2017/","publishdate":"2021-10-09T17:51:12.515876Z","relpermalink":"/publication/fontaine-scalable-2017/","section":"publication","summary":"","tags":[],"title":"Scalable source localization with multichannel α-stable distributions","type":"publication"},{"authors":["M. Fontaine","C. Vanwynsberghe","A. Liutkus","R. Badeau"],"categories":[],"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615889017,"objectID":"a28e1fa4e8bf6969e2804f1023d5a495","permalink":"https://matfontaine.github.io/publication/scalablefontaine-17/","publishdate":"2021-03-16T10:04:14.057533Z","relpermalink":"/publication/scalablefontaine-17/","section":"publication","summary":"","tags":[],"title":"Scalable source localization with multichannel α-stable distributions","type":"publication"},{"authors":["Mathieu Fontaine","Charles Vanwynsberghe","Antoine Liutkus","Roland Badeau"],"categories":[],"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615889017,"objectID":"28cd2cac61a1a53faac65fe6ccc6b39c","permalink":"https://matfontaine.github.io/publication/fontaine-2017-sketching/","publishdate":"2021-03-16T10:04:14.218709Z","relpermalink":"/publication/fontaine-2017-sketching/","section":"publication","summary":"","tags":[],"title":"Sketching for nearfield acoustic imaging of heavy-tailed sources","type":"publication"},{"authors":["Mathieu Fontaine","Charles Vanwynsberghe","Antoine Liutkus","Roland Badeau"],"categories":[],"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1633801872,"objectID":"876935694b5b3c2f6ce32fc84705fabd","permalink":"https://matfontaine.github.io/publication/fontaine-sketching-2017/","publishdate":"2021-10-09T17:51:12.696708Z","relpermalink":"/publication/fontaine-sketching-2017/","section":"publication","summary":"","tags":[],"title":"Sketching for nearfield acoustic imaging of heavy-tailed sources","type":"publication"},{"authors":null,"categories":null,"content":"Courses 1st-year Engineer School MDI-104 (Theory \u0026amp; Probability) SI-101 (Basics for signal processing) → project-based learning 2nd-year Engineer School TSIA202a (Time series, AR/ARMA etc.) TSIA202b (Periodogram, HR methods etc.) TSIA206 (Audio Source Separation) Student and Adult Project (2021-2022) - Projet Fil Rouge (”anomaly detection” with EDF Sinclair) (2021-2022) - Projet d’application musicales - ATIAM (audio source separation in a real acoustic environment) Formation continue (energy prediction using machine learning) PhD Track project → Deep Griffin-Lim algorithm on music tracks ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"322dbaccf72a6d71f827fdb2866be935","permalink":"https://matfontaine.github.io/teaching/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/teaching/","section":"","summary":"Courses that I have been taught.","tags":null,"title":"Teaching","type":"page"}]