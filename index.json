
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":["admin"],"categories":null,"content":"After a PhD in Inria Nancy Grand-Est entitled ‚Äúalpha-stable process for signal processing‚Äù, Mathieu Fontaine was a Postdoc from October 2019 to August 2021 at RIKEN Artificial Intelligence Project (AIP) and became a guest at Kyoto University. He is now Associate Professor in T√©l√©com Paris. His interests is mainly on machine listening including, but not limited, to speech enhancement, speaker separation, source localization and music source separation using heavy-tailed probabilistic models and/or deep bayesian networks with also applications in augmented reality.\n","date":1704067200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1728943210,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"After a PhD in Inria Nancy Grand-Est entitled ‚Äúalpha-stable process for signal processing‚Äù, Mathieu Fontaine was a Postdoc from October 2019 to August 2021 at RIKEN Artificial Intelligence Project (AIP) and became a guest at Kyoto University.","tags":null,"title":"Mathieu Fontaine","type":"authors"},{"authors":["Thomas Serre","Mathieu Fontaine","√âric Benhaim","Geoffroy Dutour","Slim Essid"],"categories":[],"content":"","date":1704067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1728943209,"objectID":"5d045c78011c3d3c447bfbda290b43ca","permalink":"https://matfontaine.github.io/publication/serre-2024-lightweight/","publishdate":"2024-10-14T22:00:09.355505Z","relpermalink":"/publication/serre-2024-lightweight/","section":"publication","summary":"","tags":["selected"],"title":"A lightweight dual-stage framework for personalized speech enhancement based on DeepFilterNet2","type":"publication"},{"authors":["Haocheng Liu","Teysir Baoueb","Mathieu Fontaine","Jonathan Le Roux","Gael Richard"],"categories":[],"content":"","date":1704067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1728943209,"objectID":"22b94a7632d87080013d6d52dc4113dc","permalink":"https://matfontaine.github.io/publication/liu-2024-gla/","publishdate":"2024-10-14T22:00:09.187096Z","relpermalink":"/publication/liu-2024-gla/","section":"publication","summary":"","tags":["selected"],"title":"GLA-Grad: A Griffin-Lim Extended Waveform Generation Diffusion Model","type":"publication"},{"authors":["Anton Emelchenkov","Mathieu Fontaine","Yves Grenier","Herv√© Mah√©","Fran√ßois Roueff"],"categories":[],"content":"","date":1704067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1728943209,"objectID":"2891777fb95f7a331f8f965852e4d367","permalink":"https://matfontaine.github.io/publication/emelchenkov-2024-multifrequency/","publishdate":"2024-10-14T22:00:09.69372Z","relpermalink":"/publication/emelchenkov-2024-multifrequency/","section":"publication","summary":"","tags":[],"title":"Multifrequency Highly Oscillating Aperiodic Amplitude Estimation for Nonlinear Chirp Signal","type":"publication"},{"authors":["Elio Gruttadauria","Mathieu Fontaine","Slim Essid"],"categories":[],"content":"","date":1704067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1728943209,"objectID":"34eb0f4ae530f913a91c51eb716ec9ee","permalink":"https://matfontaine.github.io/publication/gruttadauria-2024-online/","publishdate":"2024-10-14T22:00:09.019591Z","relpermalink":"/publication/gruttadauria-2024-online/","section":"publication","summary":"","tags":[],"title":"Online speaker diarization of meetings guided by speech separation","type":"publication"},{"authors":["Victor Letzelter","Mathieu Fontaine","Micka√´l Chen","Patrick P√©rez","Slim Essid","Gael Richard"],"categories":[],"content":"","date":1704067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1728943208,"objectID":"ce8d500087d2cd574691c4727ef21827","permalink":"https://matfontaine.github.io/publication/letzelter-2024-resilient/","publishdate":"2024-10-14T22:00:08.509161Z","relpermalink":"/publication/letzelter-2024-resilient/","section":"publication","summary":"","tags":["selected"],"title":"Resilient Multiple Choice Learning: A learned scoring scheme with application to audio scene analysis","type":"publication"},{"authors":["Liam Kelley","Diego Di Carlo","Aditya Arie Nugraha","Mathieu Fontaine","Yoshiaki Bando","Kazuyoshi Yoshii"],"categories":[],"content":"","date":1704067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1728943210,"objectID":"fa90463c858bab3ee4d4fb4a62b57b6e","permalink":"https://matfontaine.github.io/publication/kelley-2024-rir/","publishdate":"2024-10-14T22:00:10.027423Z","relpermalink":"/publication/kelley-2024-rir/","section":"publication","summary":"","tags":["selected"],"title":"RIR-in-a-Box: Estimating Room Acoustics from 3D Mesh Data through Shoebox Approximation","type":"publication"},{"authors":["Yoto Fujita","Aditya Arie Nugraha","Diego Di Carlo","Yoshiaki Bando","Mathieu Fontaine","Kazuyoshi Yoshii"],"categories":[],"content":"","date":1704067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1728943210,"objectID":"91a588d165074ac743bc7d13f06738ed","permalink":"https://matfontaine.github.io/publication/fujita-2024-run/","publishdate":"2024-10-14T22:00:10.194237Z","relpermalink":"/publication/fujita-2024-run/","section":"publication","summary":"","tags":[],"title":"Run-Time Adaptation of Neural Beamforming for Robust Speech Dereverberation and Denoising","type":"publication"},{"authors":["Teysir Baoueb","Haocheng Liu","Mathieu Fontaine","Jonathan Le Roux","Gael Richard"],"categories":[],"content":"","date":1704067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1728943208,"objectID":"85051706125eb13701080ff2c9ac1d48","permalink":"https://matfontaine.github.io/publication/baoueb-2024-specdiff/","publishdate":"2024-10-14T22:00:08.677541Z","relpermalink":"/publication/baoueb-2024-specdiff/","section":"publication","summary":"","tags":["selected"],"title":"SpecDiff-GAN: A Spectrally-Shaped Noise Diffusion GAN for Speech and Music Synthesis","type":"publication"},{"authors":["Louis Bahrman","Mathieu Fontaine","Jonathan Le Roux","Ga√´l Richard"],"categories":[],"content":"","date":1704067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1728943210,"objectID":"d411542df4842a69fbdbcbc6fb02483b","permalink":"https://matfontaine.github.io/publication/bahrman-2024-speech/","publishdate":"2024-10-14T22:00:09.859751Z","relpermalink":"/publication/bahrman-2024-speech/","section":"publication","summary":"","tags":["selected"],"title":"Speech dereverberation constrained on room impulse response characteristics","type":"publication"},{"authors":["Victor Letzelter","David Perera","C√©dric Rommel","Mathieu Fontaine","Slim Essid","Gael Richard","Patrick P√©rez"],"categories":[],"content":"","date":1704067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1728943209,"objectID":"d180a03c50f50c01d58436018100cf5c","permalink":"https://matfontaine.github.io/publication/letzelter-2024-winner/","publishdate":"2024-10-14T22:00:09.524901Z","relpermalink":"/publication/letzelter-2024-winner/","section":"publication","summary":"","tags":[],"title":"Winner-takes-all learners are geometry-aware conditional density estimators","type":"publication"},{"authors":["Diego Di Carlo","Aditya Arie Nugraha","Mathieu Fontaine","Kazuyoshi Yoshii"],"categories":[],"content":"","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1728943209,"objectID":"ac72fad4eec76f5eb9f93f53f1e7df8a","permalink":"https://matfontaine.github.io/publication/di-2023-neural/","publishdate":"2024-10-14T22:00:08.852443Z","relpermalink":"/publication/di-2023-neural/","section":"publication","summary":"","tags":["selected"],"title":"Neural steerer: Novel steering vector synthesis with a causal neural field over frequency and source positions","type":"publication"},{"authors":["Aditya Arie Nugraha","Diego Di Carlo","Yoshiaki Bando","Mathieu Fontaine","Kazuyoshi Yoshii"],"categories":[],"content":"","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1728943208,"objectID":"572735b01a92cfd5109217b1405a0c1e","permalink":"https://matfontaine.github.io/publication/nugraha-2023-time/","publishdate":"2024-10-14T22:00:08.336572Z","relpermalink":"/publication/nugraha-2023-time/","section":"publication","summary":"","tags":[],"title":"Time-Domain Audio Source Separation Based on Gaussian Processes with Deep Kernel Learning","type":"publication"},{"authors":["Kouhei Sekiguchi","Yoshiaki Bando","Aditya Arie Nugraha","Mathieu Fontaine","Kazuyoshi Yoshii","Tatsuya Kawahara"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1728943208,"objectID":"840c101abd43e7f56c2e936f9f744076","permalink":"https://matfontaine.github.io/publication/sekiguchi-2022-autoregressive/","publishdate":"2024-10-14T22:00:08.170911Z","relpermalink":"/publication/sekiguchi-2022-autoregressive/","section":"publication","summary":"","tags":[],"title":"Autoregressive Moving Average Jointly-Diagonalizable Spatial Covariance Analysis for Joint Source Separation and Dereverberation","type":"publication"},{"authors":["Kouhei Sekiguchi","Aditya Arie Nugraha","Yicheng Du","Yoshiaki Bando","Mathieu Fontaine","Kazuyoshi Yoshii"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1728943207,"objectID":"f18f93509c19b590dfc1fd221ee8a261","permalink":"https://matfontaine.github.io/publication/sekiguchi-2022-direction/","publishdate":"2024-10-14T22:00:07.66127Z","relpermalink":"/publication/sekiguchi-2022-direction/","section":"publication","summary":"","tags":[],"title":"Direction-aware adaptive online neural speech enhancement with an augmented reality headset in real noisy conversational environments","type":"publication"},{"authors":["Yicheng Du","Aditya Arie Nugraha","Kouhei Sekiguchi","Yoshiaki Bando","Mathieu Fontaine","Kazuyoshi Yoshii"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1728943207,"objectID":"06e81503652eecf1057d18ab556a695e","permalink":"https://matfontaine.github.io/publication/du-2022-direction/","publishdate":"2024-10-14T22:00:07.832036Z","relpermalink":"/publication/du-2022-direction/","section":"publication","summary":"","tags":["selected"],"title":"Direction-Aware Joint Adaptation of Neural Speech Enhancement and Recognition in Real Multiparty Conversational Environments","type":"publication"},{"authors":["Aditya Arie Nugraha","Kouhei Sekiguchi","Mathieu Fontaine","Yoshiaki Bando","Kazuyoshi Yoshii"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1728943208,"objectID":"428081c6ae27a8e9151371879579ad7f","permalink":"https://matfontaine.github.io/publication/nugraha-2022-dnn/","publishdate":"2024-10-14T22:00:08.000762Z","relpermalink":"/publication/nugraha-2022-dnn/","section":"publication","summary":"","tags":[],"title":"DNN-free Low-Latency Adaptive Speech Enhancement Based on Frame-Online Beamforming Powered by Block-Online Fastmnmf","type":"publication"},{"authors":["Mathieu Fontaine","Diego Di Carlo","Kouhei Sekiguchi","Aditya Arie Nugraha","Yoshiaki Bando","Kazuyoshi Yoshii"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1728943207,"objectID":"c5c4f09ead76263bbf0c832649993068","permalink":"https://matfontaine.github.io/publication/fontaine-2022-elliptically/","publishdate":"2024-10-14T22:00:07.153683Z","relpermalink":"/publication/fontaine-2022-elliptically/","section":"publication","summary":"","tags":[],"title":"Elliptically Contoured Alpha-Stable Representation for MUSIC-Based Sound Source Localization","type":"publication"},{"authors":["Aditya Arie Nugraha","Kouhei Sekiguchi","Mathieu Fontaine","Yoshiaki Bando","Kazuyoshi Yoshii"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1728943207,"objectID":"5a4702c75669d6e872c6fc3878bcc59c","permalink":"https://matfontaine.github.io/publication/nugraha-2022-flow/","publishdate":"2024-10-14T22:00:07.321947Z","relpermalink":"/publication/nugraha-2022-flow/","section":"publication","summary":"","tags":[],"title":"Flow-based fast multichannel nonnegative matrix factorization for blind source separation","type":"publication"},{"authors":["Mathieu Fontaine","Kouhei Sekiguchi","Aditya Arie Nugraha","Yoshiaki Bando","Kazuyoshi Yoshii"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1728943207,"objectID":"c737d12a210e280fd6d32a2e968e331e","permalink":"https://matfontaine.github.io/publication/fontaine-2022-generalized/","publishdate":"2024-10-14T22:00:07.491362Z","relpermalink":"/publication/fontaine-2022-generalized/","section":"publication","summary":"","tags":["selected"],"title":"Generalized Fast Multichannel Nonnegative Matrix Factorization Based on Gaussian Scale Mixtures for Blind Source Separation","type":"publication"},{"authors":["Mathieu Fontaine","Kouhei Sekiguchi","Aditya Arie Nugraha","Yoshiaki Bando","Kazuyoshi Yoshii"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1728943207,"objectID":"10373a7cf875a76fbd7748418b17503b","permalink":"https://matfontaine.github.io/publication/fontaine-2021-alpha/","publishdate":"2024-10-14T22:00:06.986487Z","relpermalink":"/publication/fontaine-2021-alpha/","section":"publication","summary":"","tags":[],"title":"Alpha-Stable Autoregressive Fast Multichannel Nonnegative Matrix Factorization for Joint Speech Enhancement and Dereverberation","type":"publication"},{"authors":["Kouhei Sekiguchi","Yoshiaki Bando","Aditya Arie Nugraha","Mathieu Fontaine","Kazuyoshi Yoshii"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1728943206,"objectID":"e5f71b7682c57fe5c9f859ba53a3f73b","permalink":"https://matfontaine.github.io/publication/sekiguchi-2021-autoregressive/","publishdate":"2024-10-14T22:00:06.654603Z","relpermalink":"/publication/sekiguchi-2021-autoregressive/","section":"publication","summary":"","tags":[],"title":"Autoregressive fast multichannel nonnegative matrix factorization for joint blind source separation and dereverberation","type":"publication"},{"authors":["Kazuyoshi Yoshii","Kouhei Sekiguchi","Yoshiaki Bando","Mathieu Fontaine","Aditya Arie Nugraha"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1728943206,"objectID":"84d90e8a19e26e92cb433d6878fa9781","permalink":"https://matfontaine.github.io/publication/yoshii-2021-fast/","publishdate":"2024-10-14T22:00:05.979533Z","relpermalink":"/publication/yoshii-2021-fast/","section":"publication","summary":"","tags":[],"title":"Fast multichannel correlated tensor factorization for blind source separation","type":"publication"},{"authors":["Yoshiaki Bando","Kouhei Sekiguchi","Yoshiki Masuyama","Aditya Arie Nugraha","Mathieu Fontaine","Kazuyoshi Yoshii"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1728943206,"objectID":"0266765e823576cabcd3851d18fb7eae","permalink":"https://matfontaine.github.io/publication/bando-2021-neural/","publishdate":"2024-10-14T22:00:06.819353Z","relpermalink":"/publication/bando-2021-neural/","section":"publication","summary":"","tags":[],"title":"Neural full-rank spatial covariance analysis for blind source separation","type":"publication"},{"authors":["Yicheng Du","Kouhei Sekiguchi","Yoshiaki Bando","Aditya Arie Nugraha","Mathieu Fontaine","Kazuyoshi Yoshii","Tatsuya Kawahara"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1728943206,"objectID":"79a66b2024804171f15feb8352fcdddb","permalink":"https://matfontaine.github.io/publication/du-2021-semi/","publishdate":"2024-10-14T22:00:06.157565Z","relpermalink":"/publication/du-2021-semi/","section":"publication","summary":"","tags":[],"title":"Semi-supervised Multichannel Speech Separation Based on a Phone-and Speaker-Aware Deep Generative Model of Speech Spectrograms","type":"publication"},{"authors":["Mathieu Fontaine","Âê≥ÊÅ©ÈÅî"],"categories":["Demo","ÊïôÁ®ã"],"content":"import libr print(\u0026#39;hello\u0026#39;) Overview The Wowchemy website builder for Hugo, along with its starter templates, is designed for professional creators, educators, and teams/organizations - although it can be used to create any kind of site The template can be modified and customised to suit your needs. It‚Äôs a good platform for anyone looking to take control of their data and online identity whilst having the convenience to start off with a no-code solution (write in Markdown and customize with YAML parameters) and having flexibility to later add even deeper personalization with HTML and CSS You can work with all your favourite tools and apps with hundreds of plugins and integrations to speed up your workflows, interact with your readers, and much more Get Started üëâ Create a new site üìö Personalize your site üí¨ Chat with the Wowchemy community or Hugo community üê¶ Twitter: @wowchemy @GeorgeCushen #MadeWithWowchemy üí° Request a feature or report a bug for Wowchemy ‚¨ÜÔ∏è Updating Wowchemy? View the Update Tutorial and Release Notes Crowd-funded open-source software To help us develop this template and software sustainably under the MIT license, we ask all individuals and businesses that use it to help support its ongoing maintenance and development via sponsorship.\n‚ù§Ô∏è Click here to become a sponsor and help support Wowchemy‚Äôs future ‚ù§Ô∏è As a token of appreciation for sponsoring, you can unlock these awesome rewards and extra features ü¶Ñ‚ú®\nEcosystem Hugo Academic CLI: Automatically import publications from BibTeX Inspiration Check out the latest demo of what you‚Äôll get in less than 10 minutes, or view the showcase of personal, project, and business sites.\nFeatures Page builder - Create anything with widgets and elements Edit any type of content - Blog posts, publications, talks, slides, projects, and more! Create content in Markdown, Jupyter, or RStudio Plugin System - Fully customizable color and font themes Display Code and Math - Code highlighting and LaTeX math supported Integrations - Google Analytics, Disqus commenting, Maps, Contact Forms, and more! Beautiful Site - Simple and refreshing one page design Industry-Leading SEO - Help get your website found on search engines and social media Media Galleries - Display your images and videos with captions in a customizable gallery Mobile Friendly - Look amazing on every screen with a mobile friendly version of your site Multi-language - 34+ language packs including English, ‰∏≠Êñá, and Portugu√™s Multi-user - Each author gets their own profile page Privacy Pack - Assists with GDPR Stand Out - Bring your site to life with animation, parallax backgrounds, and scroll effects One-Click Deployment - No servers. No databases. Only files. Themes Wowchemy and its templates come with automatic day (light) and night (dark) mode built-in. Alternatively, visitors can choose their preferred mode - click the moon icon in the top right of the Demo to see it in action! Day/night mode can also be disabled by the site admin in params.toml.\nChoose a stunning theme and font for your site. Themes are fully customizable.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"279b9966ca9cf3121ce924dca452bb1c","permalink":"https://matfontaine.github.io/post/getting-started/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/post/getting-started/","section":"post","summary":"Welcome üëã We know that first impressions are important, so we've populated your new site with some initial content to help you get familiar with everything in no time.","tags":["Academic","ÂºÄÊ∫ê"],"title":"Welcome to Wowchemy, the website builder for Hugo","type":"post"},{"authors":["Aditya Arie Nugraha","Kouhei Sekiguchi","Mathieu Fontaine","Yoshiaki Bando","Kazuyoshi Yoshii"],"categories":[],"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1728943206,"objectID":"f663f441704b7cd49167e773cd65b70c","permalink":"https://matfontaine.github.io/publication/nugraha-2020-flow/","publishdate":"2024-10-14T22:00:06.489227Z","relpermalink":"/publication/nugraha-2020-flow/","section":"publication","summary":"","tags":[],"title":"Flow-based independent vector analysis for blind source separation","type":"publication"},{"authors":["Mathieu Fontaine","Roland Badeau","Antoine Liutkus"],"categories":[],"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1728943205,"objectID":"8e862ef198cfe958b58346e0a3329b39","permalink":"https://matfontaine.github.io/publication/fontaine-2020-separation/","publishdate":"2024-10-14T22:00:05.812575Z","relpermalink":"/publication/fontaine-2020-separation/","section":"publication","summary":"","tags":[],"title":"Separation of alpha-stable random vectors","type":"publication"},{"authors":["Mathieu Fontaine","Kouhei Sekiguchi","Aditya Arie Nugraha","Kazuyoshi Yoshii"],"categories":[],"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1728943206,"objectID":"3e285db94f44ba731cc6f889fc915fca","permalink":"https://matfontaine.github.io/publication/fontaine-2020-unsupervised/","publishdate":"2024-10-14T22:00:06.326094Z","relpermalink":"/publication/fontaine-2020-unsupervised/","section":"publication","summary":"","tags":[],"title":"Unsupervised Robust Speech Enhancement Based on Alpha-Stable Fast Multichannel Nonnegative Matrix Factorization","type":"publication"},{"authors":null,"categories":null,"content":"Wowchemy is designed to give technical content creators a seamless experience. You can focus on the content and Wowchemy handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.\nOn this page, you‚Äôll find some examples of the types of technical content that can be rendered with Wowchemy.\nExamples Code Wowchemy supports a Markdown extension for highlighting code syntax. You can customize the styles under the syntax_highlighter option in your config/_default/params.yaml file.\n```python import pandas as pd data = pd.read_csv(\u0026#34;data.csv\u0026#34;) data.head() ``` renders as\nimport pandas as pd data = pd.read_csv(\u0026#34;data.csv\u0026#34;) data.head() Mindmaps Wowchemy supports a Markdown extension for mindmaps.\nSimply insert a Markdown markmap code block and optionally set the height of the mindmap as shown in the example below.\nA simple mindmap defined as a Markdown list:\n```markmap {height=\u0026#34;200px\u0026#34;} - Hugo Modules - wowchemy - wowchemy-plugins-netlify - wowchemy-plugins-netlify-cms - wowchemy-plugins-reveal ``` renders as\n- Hugo Modules - wowchemy - wowchemy-plugins-netlify - wowchemy-plugins-netlify-cms - wowchemy-plugins-reveal A more advanced mindmap with formatting, code blocks, and math:\n```markmap - Mindmaps - Links - [Wowchemy Docs](https://wowchemy.com/docs/) - [Discord Community](https://discord.gg/z8wNYzb) - [GitHub](https://github.com/wowchemy/wowchemy-hugo-themes) - Features - Markdown formatting - **inline** ~~text~~ *styles* - multiline text - `inline code` - ```js console.log(\u0026#39;hello\u0026#39;); console.log(\u0026#39;code block\u0026#39;); ``` - Math: $x = {-b \\pm \\sqrt{b^2-4ac} \\over 2a}$ ``` renders as\n- Mindmaps - Links - [Wowchemy Docs](https://wowchemy.com/docs/) - [Discord Community](https://discord.gg/z8wNYzb) - [GitHub](https://github.com/wowchemy/wowchemy-hugo-themes) - Features - Markdown formatting - **inline** ~~text~~ *styles* - multiline text - `inline code` - ```js console.log(\u0026#39;hello\u0026#39;); console.log(\u0026#39;code block\u0026#39;); ``` - Math: $x = {-b \\pm \\sqrt{b^2-4ac} \\over 2a}$ Charts Wowchemy supports the popular Plotly format for interactive charts.\nSave your Plotly JSON in your page folder, for example line-chart.json, and then add the {{\u0026lt; chart data=\u0026#34;line-chart\u0026#34; \u0026gt;}} shortcode where you would like the chart to appear.\nDemo:\nYou might also find the Plotly JSON Editor useful.\nMath Wowchemy supports a Markdown extension for $\\LaTeX$ math. You can enable this feature by toggling the math option in your config/_default/params.yaml file.\nTo render inline or block math, wrap your LaTeX math with {{\u0026lt; math \u0026gt;}}$...${{\u0026lt; /math \u0026gt;}} or {{\u0026lt; math \u0026gt;}}$$...$${{\u0026lt; /math \u0026gt;}}, respectively. (We wrap the LaTeX math in the Wowchemy math shortcode to prevent Hugo rendering our math as Markdown. The math shortcode is new in v5.5-dev.)\nExample math block:\n{{\u0026lt; math \u0026gt;}} $$ \\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |}{\\left \\|\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right \\|^2} $$ {{\u0026lt; /math \u0026gt;}} renders as\n$$\\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |}{\\left \\|\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right \\|^2}$$ Example inline math {{\u0026lt; math \u0026gt;}}$\\nabla F(\\mathbf{x}_{n})${{\u0026lt; /math \u0026gt;}} renders as $\\nabla F(\\mathbf{x}_{n})$.\nExample multi-line math using the math linebreak (\\\\):\n{{\u0026lt; math \u0026gt;}} $$f(k;p_{0}^{*}) = \\begin{cases}p_{0}^{*} \u0026amp; \\text{if }k=1, \\\\ 1-p_{0}^{*} \u0026amp; \\text{if }k=0.\\end{cases}$$ {{\u0026lt; /math \u0026gt;}} renders as\n$$ f(k;p_{0}^{*}) = \\begin{cases}p_{0}^{*} \u0026amp; \\text{if }k=1, \\\\ 1-p_{0}^{*} \u0026amp; \\text{if }k=0.\\end{cases} $$ Diagrams Wowchemy supports a Markdown extension for diagrams. You can enable this feature by toggling the diagram option in your config/_default/params.toml file or by adding diagram: true to your page front matter.\nAn example flowchart:\n```mermaid graph TD A[Hard] --\u0026gt;|Text| B(Round) B --\u0026gt; C{Decision} C --\u0026gt;|One| D[Result 1] C --\u0026gt;|Two| E[Result 2] ``` renders as\ngraph TD A[Hard] --\u0026gt;|Text| B(Round) B --\u0026gt; C{Decision} C --\u0026gt;|One| D[Result 1] C --\u0026gt;|Two| E[Result 2] An example sequence diagram:\n```mermaid sequenceDiagram Alice-\u0026gt;\u0026gt;John: Hello John, how are you? loop Healthcheck John-\u0026gt;\u0026gt;John: Fight against hypochondria end Note right of John: Rational thoughts! John--\u0026gt;\u0026gt;Alice: Great! John-\u0026gt;\u0026gt;Bob: How about you? Bob--\u0026gt;\u0026gt;John: Jolly good! ``` renders as\nsequenceDiagram Alice-\u0026gt;\u0026gt;John: Hello John, how are you? loop Healthcheck John-\u0026gt;\u0026gt;John: Fight against hypochondria end Note right of John: Rational thoughts! John--\u0026gt;\u0026gt;Alice: Great! John-\u0026gt;\u0026gt;Bob: How about you? Bob--\u0026gt;\u0026gt;John: Jolly good! An example Gantt diagram:\n```mermaid gantt section Section Completed :done, des1, 2014-01-06,2014-01-08 Active :active, des2, 2014-01-07, 3d Parallel 1 : des3, after des1, 1d Parallel 2 : des4, after des1, 1d Parallel 3 : des5, after des3, 1d Parallel 4 : des6, after des4, 1d ``` renders ‚Ä¶","date":1562889600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562889600,"objectID":"07e02bccc368a192a0c76c44918396c3","permalink":"https://matfontaine.github.io/post/writing-technical-content/","publishdate":"2019-07-12T00:00:00Z","relpermalink":"/post/writing-technical-content/","section":"post","summary":"Wowchemy is designed to give technical content creators a seamless experience. You can focus on the content and Wowchemy handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.","tags":null,"title":"Writing technical content in Markdown","type":"post"},{"authors":["Mathieu Fontaine"],"categories":[],"content":"from IPython.core.display import Image Image(\u0026#39;https://www.python.org/static/community_logos/python-logo-master-v3-TM-flattened.png\u0026#39;) print(\u0026#34;Welcome to Academic!\u0026#34;) Welcome to Academic! Install Python and JupyterLab Install Anaconda which includes Python 3 and JupyterLab.\nAlternatively, install JupyterLab with pip3 install jupyterlab.\nCreate or upload a Jupyter notebook Run the following commands in your Terminal, substituting \u0026lt;MY-WEBSITE-FOLDER\u0026gt; and \u0026lt;SHORT-POST-TITLE\u0026gt; with the file path to your Academic website folder and a short title for your blog post (use hyphens instead of spaces), respectively:\nmkdir -p \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/ cd \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/ jupyter lab index.ipynb The jupyter command above will launch the JupyterLab editor, allowing us to add Academic metadata and write the content.\nEdit your post metadata The first cell of your Jupter notebook will contain your post metadata (front matter).\nIn Jupter, choose Markdown as the type of the first cell and wrap your Academic metadata in three dashes, indicating that it is YAML front matter:\n--- title: My post\u0026#39;s title date: 2019-09-01 # Put any other Academic metadata here... --- Edit the metadata of your post, using the documentation as a guide to the available options.\nTo set a featured image, place an image named featured into your post‚Äôs folder.\nFor other tips, such as using math, see the guide on writing content with Academic.\nConvert notebook to Markdown jupyter nbconvert index.ipynb --to markdown --NbConvertApp.output_files_dir=. Example This post was created with Jupyter. The orginal files can be found at https://github.com/gcushen/hugo-academic/tree/master/exampleSite/content/post/jupyter\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567641600,"objectID":"6e929dc84ed3ef80467b02e64cd2ed64","permalink":"https://matfontaine.github.io/post/jupyter/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/post/jupyter/","section":"post","summary":"Learn how to blog in Academic using Jupyter notebooks","tags":[],"title":"Display Jupyter Notebooks with Academic","type":"post"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let‚Äôs make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://matfontaine.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Mathieu Fontaine","Aditya Arie Nugraha","Roland Badeau","Kazuyoshi Yoshii","Antoine Liutkus"],"categories":[],"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1728943205,"objectID":"08c80879057e51d654993793b3ebdd6b","permalink":"https://matfontaine.github.io/publication/fontaine-2019-cauchy/","publishdate":"2024-10-14T22:00:05.646032Z","relpermalink":"/publication/fontaine-2019-cauchy/","section":"publication","summary":"","tags":[],"title":"Cauchy multichannel speech enhancement with a deep speech prior","type":"publication"},{"authors":["Mathieu Fontaine"],"categories":[],"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1728943205,"objectID":"72325a4a25391cd7f587f2f0b6d3aaa8","permalink":"https://matfontaine.github.io/publication/fontaine-2019-processus/","publishdate":"2024-10-14T22:00:05.474284Z","relpermalink":"/publication/fontaine-2019-processus/","section":"publication","summary":"","tags":[],"title":"Processus alpha-stables pour le traitement du signal","type":"publication"},{"authors":["Mathieu Fontaine","Fabian-Robert St√∂ter","Antoine Liutkus","Umut ≈ûim≈üekli","Romain Serizel","Roland Badeau"],"categories":[],"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1728943205,"objectID":"60c5bfed0f45a3dd0e677199d4ac2257","permalink":"https://matfontaine.github.io/publication/fontaine-2018-multichannel/","publishdate":"2024-10-14T22:00:05.305713Z","relpermalink":"/publication/fontaine-2018-multichannel/","section":"publication","summary":"","tags":[],"title":"Multichannel audio modeling with elliptically stable tensor decomposition","type":"publication"},{"authors":["Mathieu Fontaine","Antoine Liutkus","Laurent Girin","Roland Badeau"],"categories":[],"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1728943205,"objectID":"5e1631363c9e3d68cd27c1289a2932aa","permalink":"https://matfontaine.github.io/publication/fontaine-2017-explaining/","publishdate":"2024-10-14T22:00:05.138922Z","relpermalink":"/publication/fontaine-2017-explaining/","section":"publication","summary":"","tags":[],"title":"Explaining the parameterized Wiener filter with alpha-stable processes","type":"publication"},{"authors":["Mathieu Fontaine","Charles Vanwynsberghe","Antoine Liutkus","Roland Badeau"],"categories":[],"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1728943205,"objectID":"9457093a9732077ca87264fbb3e15102","permalink":"https://matfontaine.github.io/publication/fontaine-2017-scalable/","publishdate":"2024-10-14T22:00:04.954125Z","relpermalink":"/publication/fontaine-2017-scalable/","section":"publication","summary":"","tags":[],"title":"Scalable source localization with multichannel alpha-stable distributions","type":"publication"},{"authors":["Mathieu Fontaine","Charles Vanwynsberghe","Antoine Liutkus","Roland Badeau"],"categories":[],"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1728943204,"objectID":"28cd2cac61a1a53faac65fe6ccc6b39c","permalink":"https://matfontaine.github.io/publication/fontaine-2017-sketching/","publishdate":"2024-10-14T21:58:40.026778Z","relpermalink":"/publication/fontaine-2017-sketching/","section":"publication","summary":"","tags":[],"title":"Sketching for nearfield acoustic imaging of heavy-tailed sources","type":"publication"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"e8f8d235e8e7f2efd912bfe865363fc3","permalink":"https://matfontaine.github.io/project/example/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/example/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Example Project","type":"project"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"d1311ddf745551c9e117aa4bb7e28516","permalink":"https://matfontaine.github.io/project/external-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/external-project/","section":"project","summary":"An example of linking directly to an external project website using `external_link`.","tags":["Demo"],"title":"External Project","type":"project"},{"authors":null,"categories":null,"content":"Courses üßëüèª‚Äçüéì 1st-year Engineer School MDI-104 ‚Üí Theory \u0026amp; Probability (slides in French) SI-101 ‚Üí Fundamentals for signal processing (project-based learning) 2nd-year Engineer School TSIA202a ‚ÜíTime series, AR/ARMA ‚Ä¶ TSIA202b ‚Üí Periodogram, HR methods ‚Ä¶ TSIA206 ‚Üí Audio Source Separation (slides) Student and Adult Project üöÄ Projet Fil Rouge, Projet d‚Äôapplication musicales (PAM) - ATIAM, Formation continue, PhD Track project PACT (Project for 1st-year Engineer student) PACT on MFCC here in French PACT on CHROMA here in French PACT on Audio source Localization here in French PACT on TRANSITION here in French ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"300db838c7a68c4fd14037dd038d2e1c","permalink":"https://matfontaine.github.io/courses/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/","section":"","summary":"Courses üßëüèª‚Äçüéì 1st-year Engineer School MDI-104 ‚Üí Theory \u0026 Probability (slides in French) SI-101 ‚Üí Fundamentals for signal processing (project-based learning) 2nd-year Engineer School TSIA202a ‚ÜíTime series, AR/ARMA ‚Ä¶ TSIA202b ‚Üí Periodogram, HR methods ‚Ä¶ TSIA206 ‚Üí Audio Source Separation (slides) Student and Adult Project üöÄ Projet Fil Rouge, Projet d‚Äôapplication musicales (PAM) - ATIAM, Formation continue, PhD Track project PACT (Project for 1st-year Engineer student) PACT on MFCC here in French PACT on CHROMA here in French PACT on Audio source Localization here in French PACT on TRANSITION here in French ","tags":null,"title":"Courses","type":"page"},{"authors":null,"categories":null,"content":"üí∞ Fundings (2024-2028) ‚Üí CIEDS Project (FakeDetect) on multimodality for deep fake detection (Collaborator) (~150k‚Ç¨) (2024) ‚Üí HI! Project (DARHAM) on dataset of augmented reality headset for acoustic matching (P.I.) (~10k‚Ç¨) (2023-2026) ‚Üí ANR JCJC (SAROUMANE) on speaker diarization (P.I.) (~270k‚Ç¨) (2022-2024) ‚Üí HI! Project (MASTER-AI) on stochastic models for artificial intelligence (P.I.) (~10k‚Ç¨) üë®üèª‚Äçüè´ Current Students PhD Students (2022 - 2025) ‚Üí Louis BAHRMAN (dereverberation) Topic: Speech/Audio dereverberation by hybrid deep neural modelling Supervisors: Ga√´l RICHARD \u0026amp; Mathieu FONTAINE (T√©l√©com Paris) (2022 - 2025) ‚Üí Elio GRUTTADAURIA (speaker diarization) Topic: Online Multichannel Speaker Diarization and Localisation in the Wild Supervisors: Slim ESSID \u0026amp; Mathieu FONTAINE (T√©l√©com Paris) (2023 - 2026) ‚Üí Anton EMELCHENKOV (anomaly detection) Topic: Detecting outliers in locally stationary time series Supervisors: Fran√ßois ROUEFF, Mathieu FONTAINE \u0026amp; Yves GRENIER (T√©l√©com Paris) Herv√© MAHE (Val√©o) (2023 - 2026) ‚Üí Victor LETZELTER (sound analysis / automated driving) Topic: Spatio-temporal analysis of sound scenes for assisted and automated driving Supervisors: Ga√´l RICHARD \u0026amp; Mathieu FONTAINE (T√©l√©com Paris) Patrick PEREZ (Val√©o) (2023 - 2026) ‚Üí Thomas SERRE (personalized speech enhancement) Topic: Personalized Speech Enhancement in real-time through Deep Learning Supervisors: Slim ESSID \u0026amp; Mathieu FONTAINE (T√©l√©com Paris) Eric BENHAIM (Orosound) (2023 - 2026) ‚Üí Louis LALAY (separation and dereverberation) Topic: Joint separation and dereverberation of moving speakers Supervisors: Roland BADEAU \u0026amp; Mathieu FONTAINE (T√©l√©com Paris) (2023 - 2026) ‚Üí Sicheng MAO (speaker diarization) Topic: Generative Models for speaker diarization Supervisors: Roland BADEAU \u0026amp; Mathieu FONTAINE (T√©l√©com Paris) Anthony LARCHER (LIUM Le Mans) üë®üèª‚Äçüíª Past Students Interns \u0026amp; Research Engineers Jean-Daniel PASCAL (Audio source separation), Eloi MASSOULIE (tracking of mobile sound sources), , Teysir BAOUEB (Audio diffusion model \u0026amp; GAN), Haocheng LIU (guided gradient descent through multivariate alpha-stable models), Polina BARABANSHCHIKOVA (RKHS and diffusion models), Wen YANG (forecasting demand for electric vehicle) and Liam KELLEY (Research Engineer on DARHAM project) üßëüèª‚Äçüî¨ Others I am also guest scientist at RIKEN AIP in Sound Scene Understanding team of Kazuyoshi YOSHII in Kyoto, Japan (click here to visit their website) I involve in the (Audio Data Analysis and Signal Processing) ADASP group at T√©l√©com Paris (click here to visit their website) I involve in the (Joint Laboratory) LISTEN at T√©l√©com Paris (click here to visit their website) ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f1d044c0738ab9f19347f15c290a71a1","permalink":"https://matfontaine.github.io/research/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/research/","section":"","summary":"üí∞ Fundings (2024-2028) ‚Üí CIEDS Project (FakeDetect) on multimodality for deep fake detection (Collaborator) (~150k‚Ç¨) (2024) ‚Üí HI! Project (DARHAM) on dataset of augmented reality headset for acoustic matching (P.I.) (~10k‚Ç¨) (2023-2026) ‚Üí ANR JCJC (SAROUMANE) on speaker diarization (P.","tags":null,"title":"Research/Projects","type":"page"}]